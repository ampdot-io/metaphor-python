{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "070871f0-d180-416b-a8cd-e76ff966f562",
      "metadata": {
        "id": "070871f0-d180-416b-a8cd-e76ff966f562"
      },
      "source": [
        "# Metaphor Researcher\n",
        "---\n",
        "In this example, we will build Metaphor Researcher, a Python app that given a research topic, automatically searches for different sources about the topic with Metaphor and synthesizes the searched contents into a research report. [Check it out on Colab!](https://colab.research.google.com/drive/1BaGhYb394cQSavFo7wiu95Rt_G1mtfY9)\n",
        "\n",
        "To play with this code, first we need a [Metaphor API key](https://dashboard.metaphor.systems/overview) and an [OpenAI API key](https://platform.openai.com/api-keys). Get 1000 Metaphor searches per month free just for [signing up](https://dashboard.metaphor.systems/overview)!\n",
        "\n",
        "Let's import the Metaphor and OpenAI SDKs and put in our API keys to create a client object for each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e9e0882-d0ed-4c19-a404-f0957ef2b677",
      "metadata": {
        "id": "1e9e0882-d0ed-4c19-a404-f0957ef2b677"
      },
      "outputs": [],
      "source": [
        "# install Metaphor and OpenAI SDKs\n",
        "!pip install metaphor_python\n",
        "!pip install openai\n",
        "\n",
        "from google.colab import userdata # comment this out if you're not using Colab\n",
        "\n",
        "METAPHOR_API_KEY = userdata.get('METAPHOR_API_KEY') # replace with your api key, or add to Colab Secrets\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY') # replace with your api key, or add to Colab Secrets\n",
        "\n",
        "from metaphor_python import Metaphor\n",
        "import openai\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "metaphor = Metaphor(METAPHOR_API_KEY);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af45bf85-f40d-4f27-a697-083c1fc37b08",
      "metadata": {
        "id": "af45bf85-f40d-4f27-a697-083c1fc37b08"
      },
      "source": [
        "Since we'll be making several calls to the OpenAI API to get a completion from GPT 3.5-turbo, let's make a simple utility wrapper function so we can pass in the system and user messages directly, and get the LLM's response back as a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ad7dbb0-3732-4039-a818-fb74c79fe7f9",
      "metadata": {
        "id": "1ad7dbb0-3732-4039-a818-fb74c79fe7f9"
      },
      "outputs": [],
      "source": [
        "def get_llm_response(system='You are a helpful assistant.', user = '', temperature = 1, model = 'gpt-3.5-turbo'):\n",
        "    completion = openai.chat.completions.create(\n",
        "        model=model,\n",
        "        temperature=temperature,\n",
        "        messages=[\n",
        "            {'role': 'system', 'content': system},\n",
        "            {'role': 'user', 'content': user},\n",
        "        ]\n",
        "    );\n",
        "    return completion.choices[0].message.content;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b15f155-fbde-42da-907a-19328321acf6",
      "metadata": {
        "id": "4b15f155-fbde-42da-907a-19328321acf6"
      },
      "source": [
        "Okay, great! Now let's start building Metaphor Researcher. The app should be able to automatically generate research reports for all kinds of different topics. Here's two to start:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "811ea07b-c9c4-42a5-bbf2-62f162aca734",
      "metadata": {
        "id": "811ea07b-c9c4-42a5-bbf2-62f162aca734"
      },
      "outputs": [],
      "source": [
        "XYZZY_TOPIC = 'xyzzy';\n",
        "ART_TOPIC = 'renaissance art';"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "344c7cd8-577c-4eb4-870e-9ed813093d43",
      "metadata": {
        "id": "344c7cd8-577c-4eb4-870e-9ed813093d43"
      },
      "source": [
        "The first thing our app has to do is decide what kind of search to do for the given topic.\n",
        "\n",
        "Metaphor offers two kinds of search: **neural** and **keyword** search. Here's how we decide:\n",
        "\n",
        "- Neural search is preferred because it lets us retrieve high quality, semantically relevant data. It is especially suitable when a topic is well-known and popularly discussed on the Internet, allowing the machine learning model to retrieve contents which are more likely recommended by real humans.  \n",
        "- Keyword search is only necessary when the topic is extremely specific, local or obscure. If the machine learning model might not know about the topic, but relevant documents can be found by directly matching the search query, keyword search is suitable.\n",
        "\n",
        "So, Metaphor Researcher is going to get a query, and it needs to automatically decide whether to use `keyword` or `neural` search to research the query based on the criteria. Sounds like a job for the LLM! But we need to write a prompt that tells it about the difference between keyword and neural search-- oh wait, we have a perfectly good explanation right there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78349d06-b8a7-4532-a567-67dea8d8716a",
      "metadata": {
        "id": "78349d06-b8a7-4532-a567-67dea8d8716a"
      },
      "outputs": [],
      "source": [
        "# Let's generalize the prompt and call the search types (1) and (2) in case the LLM is sensitive to the names. We can replace them with different names programmatically to see what works best.\n",
        "SEARCH_TYPE_EXPLANATION = \"\"\"- (1) search is preferred because it lets us retrieve high quality, up-to-date, and semantically relevant data. It is especially suitable when a topic is well-known and popularly discussed on the Internet, allowing the machine learning model to retrieve contents which are more likely recommended by real humans.\n",
        "- (2) search is only necessary when the topic is extremely specific, local or obscure. If the machine learning model might not know about the topic, but relevant documents can be found by directly matching the search query, (2) search is suitable.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac12f035-2b01-4a75-84cc-c7415d505079",
      "metadata": {
        "id": "ac12f035-2b01-4a75-84cc-c7415d505079"
      },
      "source": [
        "Here's a function that instructs the LLM to choose between the search types and give its answer in a single word. Based on its choice, we return `keyword` or `neural`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dae8625-09e5-4bcc-bed8-6427bca42873",
      "metadata": {
        "id": "4dae8625-09e5-4bcc-bed8-6427bca42873"
      },
      "outputs": [],
      "source": [
        "def decide_search_type(topic, choice_names = ['neural', 'keyword']):\n",
        "    user_message = 'Decide whether to use (1) or (2) search for the provided research topic. Output your choice in a single word: either \"(1)\" or \"(2)\". Here is a guide that will help you choose:\\n';\n",
        "    user_message += SEARCH_TYPE_EXPLANATION;\n",
        "    user_message += f'Topic: {topic}\\n';\n",
        "    user_message += 'Search type: ';\n",
        "    user_message = user_message.replace('(1)', choice_names[0]).replace('(2)', choice_names[1]);\n",
        "\n",
        "    response = get_llm_response(\n",
        "        system='You will be asked to make a choice between two options. Answer with your choice in a single word.',\n",
        "        user=user_message,\n",
        "        temperature=0\n",
        "    )\n",
        "    use_keyword = response.strip().lower().startswith(choice_names[1].lower())\n",
        "    return 'keyword' if use_keyword else 'neural';"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bc7feb5-8b8a-4bf9-b133-810414d9f5ec",
      "metadata": {
        "id": "2bc7feb5-8b8a-4bf9-b133-810414d9f5ec"
      },
      "source": [
        "Let's test it out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a517ae75-12ca-47e4-beff-4b6f0c6b793d",
      "metadata": {
        "id": "a517ae75-12ca-47e4-beff-4b6f0c6b793d",
        "outputId": "03189a03-e6f1-4cb1-cf3c-cd1d1ee9b738"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xyzzy expected: keyword, got: keyword\n",
            "renaissance art expected: neural, got: neural\n"
          ]
        }
      ],
      "source": [
        "print(XYZZY_TOPIC, 'expected: keyword, got:', decide_search_type(XYZZY_TOPIC));\n",
        "print(ART_TOPIC, 'expected: neural, got:', decide_search_type(ART_TOPIC));"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d210bad5-3741-4f45-8271-1da86db7a2c2",
      "metadata": {
        "id": "d210bad5-3741-4f45-8271-1da86db7a2c2"
      },
      "source": [
        "Great! Now we have to craft some search queries for the topic and the search type. There are two cases here: keyword search and neural search. Let's do the easy one first. LLMs already know what Google-like keyword searches look like. So let's just ask the LLM for what we want:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54b4ccaf-57a8-4074-a00d-8799927bc941",
      "metadata": {
        "id": "54b4ccaf-57a8-4074-a00d-8799927bc941",
        "outputId": "f4cbb0a7-5a87-4adb-c071-2bf736aa7586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xyzzy history\n",
            "xyzzy significance\n",
            "xyzzy applications\n"
          ]
        }
      ],
      "source": [
        "def create_keyword_query_generation_prompt(topic, n):\n",
        "    return f\"\"\"I'm writing a research report on {topic} and need help coming up with Google keyword search queries.\n",
        "Google keyword searches should just be a few words long. It should not be a complete sentence.\n",
        "Please generate a diverse list of {n} Google keyword search queries that would be useful for writing a research report on ${topic}. Do not add any formatting or numbering to the queries.\"\"\"\n",
        "\n",
        "print(get_llm_response(\n",
        "    system='The user will ask you to help generate some search queries. Respond with only the suggested queries in plain text with no extra formatting, each on it\\'s own line.',\n",
        "    user=create_keyword_query_generation_prompt(XYZZY_TOPIC, 3),\n",
        "));\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4eafb68-e672-4dfb-919e-7659daa02485",
      "metadata": {
        "id": "a4eafb68-e672-4dfb-919e-7659daa02485"
      },
      "source": [
        "Those are some good ideas!\n",
        "\n",
        "Now we have to handle the neural Metaphor search. This is tougher: you can read all about crafting good Metaphor searches [here](https://docs.metaphor.systems/reference/prompting-guide). But this is actually a really good thing: making the perfect Metaphor search is hard because Metaphor is so powerful! Metaphor allows us to express so much more nuance in our searches and gives us unparalleled ability to steer our search queries towards our real objective.\n",
        "\n",
        "We need to our app to understand our goal, what Metaphor is, and how to use it to achieve the goal. So let's just tell the LLM everything it needs to know."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6758f642-9a9b-4931-a933-3400f191efe0",
      "metadata": {
        "id": "6758f642-9a9b-4931-a933-3400f191efe0",
        "outputId": "2ef770d8-4af8-4b57-c2a6-45a6d9989c80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Check out this comprehensive website on Renaissance art: \n",
            "Discover the fascinating world of Renaissance art on this reliable webpage: \n",
            "I stumbled upon a reliable source with in-depth information about Renaissance art:\n"
          ]
        }
      ],
      "source": [
        "def create_neural_query_generation_prompt(topic, n):\n",
        "    return f\"\"\"I'm writing a research report on {topic} and need help coming up with Metaphor keyword search queries.\n",
        "Metaphor is a fully neural search engine that uses an embeddings based approach to search. Metaphor was trained on how people refer to content on the internet. The model is trained given the description to predict the link. For example, if someone tweets \"This is an amazing, scientific article about Roman architecture: <link>\", then our model is trained given the description to predict the link, and it is able to beautifully and super strongly learn associations between descriptions and the nature of the content (style, tone, entity type, etc) after being trained on many many examples. Because Metaphor was trained on examples of how people talk about links on the Internet, the actual Metaphor queries must actually be formed as if they are content recommendations that someone would make on the Internet where a highly relevant link would naturally follow the recommendation, such as the example shown above.\n",
        "Metaphor neural search queries should be phrased like a person on the Internet indicating a webpage to a friend by describing its contents. It should end in a colon :.\n",
        "Please generate a diverse list of {n} Metaphor neural search queries for informative and trustworthy sources useful for writing a research report on ${topic}. Do not add any quotations or numbering to the queries.\"\"\"\n",
        "\n",
        "print(get_llm_response(\n",
        "    system='The user will ask you to help generate some search queries. Respond with only the suggested queries in plain text with no extra formatting, each on it\\'s own line.',\n",
        "    user=create_neural_query_generation_prompt(ART_TOPIC, 3),\n",
        "    #model='gpt-4'\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6da25ed6-22a8-4a30-b446-4a1cc7be740c",
      "metadata": {
        "id": "6da25ed6-22a8-4a30-b446-4a1cc7be740c"
      },
      "source": [
        "Now let's put them together into a function that generates queries for the right search mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1521d126-420a-43c8-a9ff-df14a5bb3869",
      "metadata": {
        "id": "1521d126-420a-43c8-a9ff-df14a5bb3869"
      },
      "outputs": [],
      "source": [
        "def generate_search_queries(topic, n, searchType):\n",
        "    if(searchType != 'keyword' and searchType != 'neural'):\n",
        "        raise 'invalid searchType';\n",
        "    user_prompt = create_neural_query_generation_prompt(topic, n) if searchType == 'neural' else create_keyword_query_generation_prompt(topic, n);\n",
        "    completion = get_llm_response(\n",
        "        system='The user will ask you to help generate some search queries. Respond with only the suggested queries in plain text with no extra formatting, each on it\\'s own line.',\n",
        "        user=user_prompt,\n",
        "        temperature=1\n",
        "    )\n",
        "    queries = [s for s in completion.split('\\n') if s.strip()][:n]\n",
        "    return queries;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ec81c2e-18d5-4276-a951-af1ca0bd93d5",
      "metadata": {
        "id": "1ec81c2e-18d5-4276-a951-af1ca0bd93d5"
      },
      "source": [
        "Let's make sure it works, and check out some more queries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "843ab311-0457-4c62-9e65-75af9bc7d0f4",
      "metadata": {
        "id": "843ab311-0457-4c62-9e65-75af9bc7d0f4"
      },
      "outputs": [],
      "source": [
        "XYZZY_queries = generate_search_queries(XYZZY_TOPIC, 3, 'keyword');\n",
        "art_queries = generate_search_queries(ART_TOPIC, 3, 'neural');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6669a03-0056-4402-9974-e577c57d6c26",
      "metadata": {
        "id": "d6669a03-0056-4402-9974-e577c57d6c26",
        "outputId": "3505f8ba-fc3d-4ff5-86f6-f3e3cc0c8315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ \u001b[32m\"xyzzy definition\"\u001b[39m, \u001b[32m\"xyzzy history\"\u001b[39m, \u001b[32m\"xyzzy research studies\"\u001b[39m ]\n",
            "[\n",
            "  \u001b[32m\"- You have to check out this comprehensive guide to Renaissance art: \"\u001b[39m,\n",
            "  \u001b[32m\"- I stumbled upon an amazing website that delves into the fascinating world of Renaissance art: \"\u001b[39m,\n",
            "  \u001b[32m\"- Hey, I found a hidden gem of information about Renaissance art that you need to read:\"\u001b[39m\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "print(XYZZY_queries);\n",
        "print(art_queries);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afafe60c-e801-4901-973d-4e95a2db9022",
      "metadata": {
        "id": "afafe60c-e801-4901-973d-4e95a2db9022"
      },
      "source": [
        "Now it's time to use Metaphor to do the search, either neural or keyword:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3b3a6ca-37dd-4ad6-af92-2d16718df38a",
      "metadata": {
        "id": "a3b3a6ca-37dd-4ad6-af92-2d16718df38a"
      },
      "outputs": [],
      "source": [
        "def get_search_results(queries, type, linksPerQuery=2):\n",
        "    results = [];\n",
        "    for query in queries:\n",
        "        search_response = metaphor.search(query, type=type, num_results=linksPerQuery, use_autoprompt=False);\n",
        "        results.extend(search_response.results)\n",
        "    return results;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b33d838-1bcf-4424-a05a-cee17816379e",
      "metadata": {
        "id": "5b33d838-1bcf-4424-a05a-cee17816379e",
        "outputId": "38bd4bce-e54e-4a69-9f64-43aae74633e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  title: \u001b[32m\"Italian Renaissance Art\"\u001b[39m,\n",
            "  url: \u001b[32m\"https://www.italian-renaissance-art.com/\"\u001b[39m,\n",
            "  publishedDate: \u001b[32m\"2023-01-01\"\u001b[39m,\n",
            "  author: \u001b[1mnull\u001b[22m,\n",
            "  id: \u001b[32m\"FP6SGj5eJJohGakUpexj4g\"\u001b[39m,\n",
            "  score: \u001b[33m0.17535683512687683\u001b[39m\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "art_links = get_search_results(art_queries, 'neural');\n",
        "print(art_links[0]) # first result of six"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dae3d6a7-1450-4f70-aa27-a50326e4500e",
      "metadata": {
        "id": "dae3d6a7-1450-4f70-aa27-a50326e4500e"
      },
      "source": [
        "And to get the webpage contents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b1adb0d-bdb3-4a57-be5a-5550b5f4a8d1",
      "metadata": {
        "id": "1b1adb0d-bdb3-4a57-be5a-5550b5f4a8d1"
      },
      "outputs": [],
      "source": [
        "def get_page_contents(search_results):\n",
        "    contents_response = metaphor.get_contents(search_results);\n",
        "    return contents_response.contents;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d101ccb5-4d1f-48e6-9973-08a8f68066a6",
      "metadata": {
        "id": "d101ccb5-4d1f-48e6-9973-08a8f68066a6",
        "outputId": "a2df382c-1017-42fd-8bc1-cc015bccab77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<div><div>\n",
            "<h2>Italian Renaissance Art.<br /> A personal voyage into art history.</h2>\n",
            "<p>This site explores all the major masterpieces of Italian Renaissance Art. From the fourteenth-century period known as the\n",
            "Proto-Renaissance, championed by <a href=\"https://www.italian-renaissance-art.com/Giotto.html\">Giotto de Bondone</a> and his contemporaries, to\n",
            "the Renaissance of the fifteenth and sixteenth centuries.</p><p> Artists such as\n",
            "Masaccio, Fra Angelico, Donatello and Botticelli in addition to the High\n",
            "Renaissance masters Michelangelo, Leonardo da Vinci, Raphael, and Titian are\n",
            "key to the development of the artistic innovations of the era.</p>\n",
            "<h3>A Rebirth of Classical Antiquity.</h3>\n",
            "<p>The Renaissance, the rebirth of Art and Science, represents the pinnacle of artistic achievement, revived and confidently executed after a thousand years in the wilderness.</p><p> The need to recapture the glories of antiquity was initially fuelled by scholars from various social backgrounds. In Italy, the perception was that the power and glory of ancient Rome (broken by invading Northern tribes) could be reborn.</p><p> This was a major driving force for the beginnings of the Renaissance.<br /></p>\n",
            "<p>The Renaissance in Italy saw a move away from the medieval art of the past to a more realistic, somewhat scientific interpretation of reality. Artists began to use new methods in their paintings and sculptures like the newly re-discovered science of liner perspective championed by the architect <a href=\"https://www.italian-renaissance-art.com/Brunelleschi.html\">Filippo Brunelleschi’s</a> experiments in perspective in and around Florence.<br /></p>\n",
            "<p><a href=\"https://www.italian-renaissance-art.com/Leonardo-Da-Vinci.html\">Leonardo da Vinci</a>, <a href=\"https://www.italian-renaissance-art.com/Michelangelo.html\">Michelangelo</a>, and <a href=\"https://www.italian-renaissance-art.com/Raphael.html\">Raphael</a> are names\n",
            "that are familiar to most but the workshops of Florence, Venice and other\n",
            "city-states of Italy produced a procession of gifted and well-trained artists\n",
            "whose legacy endures to this day.</p><p> Artists such as <a href=\"https://www.italian-renaissance-art.com/Masaccio.html\">Masaccio</a>, <a href=\"https://www.italian-renaissance-art.com/Fra-Angelico.html\">Fra Angelico</a>, <a href=\"https://www.italian-renaissance-art.com/Piero-della-Francesca.html\">Piero\n",
            "Della Francesca</a>, and<a href=\"https://www.italian-renaissance-art.com/Sandro-Botticelli.html\"> Sandro Botticelli</a> are among the many names who laid the platform\n",
            "leading to the achievements of the High Renaissance in Italy and beyond.<br /></p>\n",
            "<h3>The new knowledge spreads.</h3>\n",
            "<p>The innovations’ of the <a href=\"https://www.italian-renaissance-art.com/Italian-renaissance.html\">Renaissance in Italy </a>eventually expanded to include artists working in Northern Europe. Contemporary painters from the North include <a href=\"https://www.italian-renaissance-art.com/Durer.html\">Albrecht</a><a href=\"https://www.italian-renaissance-art.com/Durer.html\"> Durer</a>, <a href=\"https://www.italian-renaissance-art.com/Hieronymus-Bosch.html\">Hieronymus </a><a href=\"https://www.italian-renaissance-art.com/Hieronymus-Bosch.html\">Bosch</a>, <a href=\"https://www.italian-renaissance-art.com/Jan-Van-Eyck.html\">Jan Van Eyck</a>, <a href=\"https://www.italian-renaissance-art.com/Van-\n"
          ]
        }
      ],
      "source": [
        "art_content = get_page_contents([link.id for link in art_links]);\n",
        "print(art_content[0].extract) # first result of six"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95d78836-27f9-46f3-aca7-c11bd8774b2e",
      "metadata": {
        "id": "95d78836-27f9-46f3-aca7-c11bd8774b2e"
      },
      "source": [
        "In just a couple lines of code, we've used Metaphor to go from some search queries to useful Internet content.\n",
        "\n",
        "The final step is to instruct the LLM to synthesize the content into a research report, including citations of the original links. We can do that by pairing the content and the urls and writing them into the prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "726512c2-907d-47d1-ac7c-741c8d48bace",
      "metadata": {
        "id": "726512c2-907d-47d1-ac7c-741c8d48bace"
      },
      "outputs": [],
      "source": [
        "def synthesize_report(topic, search_contents, content_slice = 750):\n",
        "    inputData = ''.join([\n",
        "        f'--START ITEM--\\nURL: {item.url}\\nCONTENT: {item.extract[:content_slice]}\\n--END ITEM--\\n'\n",
        "        for item in search_contents\n",
        "    ])\n",
        "    return get_llm_response(\n",
        "        system='You are a helpful research assistant. Write a report according to the user\\'s instructions.',\n",
        "        user='Input Data:\\n' + inputData + f'Write a two paragraph research report about {topic} based on the provided information. Include as many sources as possible. Provide citations in the text using footnote notation ([#]). First provide the report, followed by a single \"References\" section that lists all the URLs used, in the format [#] <url>.',\n",
        "        # model: 'gpt-4' # want a better report? use gpt-4\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a5d31a2-79ba-4dcc-8b5f-f650d3730142",
      "metadata": {
        "id": "3a5d31a2-79ba-4dcc-8b5f-f650d3730142"
      },
      "outputs": [],
      "source": [
        "art_report = synthesize_report(ART_TOPIC, art_content);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4226241-0191-487c-8899-2bd76e495570",
      "metadata": {
        "id": "c4226241-0191-487c-8899-2bd76e495570",
        "outputId": "100aa775-a568-4e20-96cb-345f30ee8b7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Research Report: Renaissance Art\n",
            "\n",
            "The Renaissance period, spanning from the 14th to the 17th century, marked a significant cultural and artistic bridge between the Middle Ages and modern history[^3]. This era, initially sparked as a cultural movement in Italy during the Late Medieval period, later spread throughout Europe, ushering in the Early Modern Age[^4]. Renaissance art emerged as a pivotal aspect of this period, embodying a rebirth and awakening in Europe[^4]. It represented a time when artists pushed the boundaries of their creativity and produced works of extraordinary beauty and intellectual prowess[^4]. The Italian Renaissance, in particular, witnessed the rise of renowned masters such as Giotto de Bondone, Masaccio, Botticelli, and Leonardo da Vinci, among others, who played vital roles in developing artistic innovations during the era[^1][^3].\n",
            "\n",
            "The artistic achievements of the Renaissance largely revolved around a rediscovery and reapplication of classical antiquity[^1]. Artists sought inspiration from ancient Greek and Roman works, incorporating classical elements into their compositions and reviving techniques like sfumato, which created a seamless blending of colors without visible brushstrokes[^0][^5]. This era not only revolutionized artistic expression but also fostered innovative developments in the realms of science, architecture, and literature, demonstrating the Renaissance's far-reaching influence[^3]. Furthermore, the enduring impact of Renaissance art is evident even today, with its timeless images continuing to captivate and inspire people around the world[^4].\n",
            "\n",
            "References:\n",
            "[0] https://stolenhistory.org/articles/leonardo-da-vinci-and-his-micro-brushes.289/#post-2981\n",
            "[1] https://www.italian-renaissance-art.com/\n",
            "[3] https://www.renaissanceart.org/\n",
            "[4] https://3quarksdaily.com/3quarksdaily/2021/11/the-madness-of-renaissance-art.html\n",
            "[5] http://www.ruf.rice.edu/~fellows/hart206/hartstudy.htm\n"
          ]
        }
      ],
      "source": [
        "print(artReport)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3b5b3ac-3ac2-4f83-a462-80b4cf516227",
      "metadata": {
        "id": "a3b5b3ac-3ac2-4f83-a462-80b4cf516227"
      },
      "source": [
        "Let's wrap up by putting it all together into one `researcher()` function that starts from a topic and returns us the finished report. We can also let Metaphor Researcher generate us a report about our keyword search topic as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd9f75d8-0360-4cd6-99bc-3b6519da088b",
      "metadata": {
        "id": "fd9f75d8-0360-4cd6-99bc-3b6519da088b"
      },
      "outputs": [],
      "source": [
        "def researcher(topic):\n",
        "    search_type = decide_search_type(topic)\n",
        "    search_queries = generate_search_queries(topic, 3, search_type)\n",
        "    print(search_queries)\n",
        "    search_results = get_search_results(search_queries, search_type)\n",
        "    print(search_results[0])\n",
        "    search_contents = get_page_contents([link.id for link in search_results])\n",
        "    print(search_contents[0])\n",
        "    report = synthesize_report(topic, search_contents)\n",
        "    return report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27317f11-697d-4c6c-9369-00896e42e3ff",
      "metadata": {
        "id": "27317f11-697d-4c6c-9369-00896e42e3ff",
        "outputId": "f955cd51-3dad-45cf-9658-5568084a1c57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ \u001b[32m\"xyzzy history\"\u001b[39m, \u001b[32m\"xyzzy uses\"\u001b[39m, \u001b[32m\"xyzzy benefits\"\u001b[39m ]\n",
            "{\n",
            "  title: \u001b[32m\"Xyzzy (computing) - Wikipedia\"\u001b[39m,\n",
            "  url: \u001b[32m\"https://en.wikipedia.org/wiki/Xyzzy_(computing)\"\u001b[39m,\n",
            "  author: \u001b[1mnull\u001b[22m,\n",
            "  id: \u001b[32m\"ac05e07a-722a-4de5-afc8-856c8192c5d2\"\u001b[39m\n",
            "}\n",
            "{\n",
            "  id: \u001b[32m\"ac05e07a-722a-4de5-afc8-856c8192c5d2\"\u001b[39m,\n",
            "  url: \u001b[32m\"https://en.wikipedia.org/wiki/Xyzzy_(computing)\"\u001b[39m,\n",
            "  title: \u001b[32m\"Xyzzy (computing)\"\u001b[39m,\n",
            "  author: \u001b[1mnull\u001b[22m,\n",
            "  extract: \u001b[32m\"<div><div>\\n\"\u001b[39m +\n",
            "    \u001b[32m\"<p>From Wikipedia, the free encyclopedia</p>\\n\"\u001b[39m +\n",
            "    \u001b[32m\"</div><div>\\n\"\u001b[39m +\n",
            "    \u001b[32m'<p>In <a href=\"https://en.wikipe'\u001b[39m... 10626 more characters\n",
            "}\n",
            "Report:\n",
            "\n",
            "Xyzzy is a term that is commonly used in computing. It can act as a metasyntactic variable or a video game cheat code[^1^]. The term originated from the Colossal Cave Adventure computer game, where it served as the first \"magic string\" that players usually encounter[^1^]. Additionally, Xyzzy is also referred to as a mnemonic memory trick used in mathematics[^3^].\n",
            "\n",
            "Furthermore, Xyzzy is associated with a leading Web3 solutions company called XYZZY, which recently announced a partnership with Kingdom Eth, the developers of a medieval-based staking game[^4^]. The collaboration aims to enhance brand awareness for both companies and make significant contributions to the Web3 industry[^4^].\n",
            "\n",
            "References:\n",
            "[1] https://en.wikipedia.org/wiki/Xyzzy_(computing)\n",
            "[3] https://en.wikipedia.org/wiki/Xyzzy_(mnemonic)\n",
            "[4] https://cointelegraph.com/press-releases/xyzzy-and-kingdom-eth-collaborate-to-revolutionize-web3-industries\n"
          ]
        }
      ],
      "source": [
        "print(researcher(XYZZY_TOPIC));"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}